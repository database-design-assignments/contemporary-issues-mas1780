# Contemporary Issues In Data
This code consists of a summary of two articles which are related to the issues faced by modern databases. 

## Article 1 Performance Issues 
[The link text you see on the web page](https://www.sciencedirect.com/science/article/pii/089571779090170R)
One of the biggest issues faced by database designers and managers is the modeling of concurrency control algorithms which are required to avoid errors which may arise due to software contention between databases. This essentially means that in real time processing, different databases are working separately and independently of one another and relying information, perhaps, to a central database. The problem that exists is that after one database is done acquiring software for data input, the other database  might have to access the new data. The problem left with us users is that while each database is doing its job, the results are not concurrent with one another. 

For tricky events which require real time processing such as collecting information about medical processes, the time-lag which occurs between databases contending one another for processing can become a big problem when we scale the problem to many GBs of data which is going through the databases. Thus designing a database has become ever more complex considering the huge amounts of data that is input and output compared to a few years ago only. Therefore, these concurrency control algorithms need constant monitoring and optimization. 

## Article 2 Secuirty, Magnitude and Patchwork 
[The link text you see on the web page](https://insidebigdata.com/2019/11/05/why-databases-are-failing-the-modern-economy/)
Considering the precious data that in automatically recorded when we decide to accept cookies and other terms of agreement on various websites, we do have the expectation that this data is secure. However, this article begs to ask the question of whether the data really is safe. So far the programmers and data analysts that work on these databases have applied patchwork to keep the existing databases up with the changing trends and exponentially growing size of the data. Instead, what is required is a complete overhaul of how the data ought to be stored and make the newer techniques much more scalable and uniform in order for different platforms and firms to understand databases rather than each group having a separate design and usage system. 

Another issue highlighted in the article was how with huge amounts of data, there needs to be a storage in the form of redundant storage warehouses. This in turn implies that data is exposed to even more nodes and thus the chances for this data to be hacked into is increasing with each passing year as data influx increases. Therefore, there is a constant need to hire cyber security individuals and could security officials who are a big part of any IT firmâ€™s net costs and thus greatly reduce avenues of research and development. 
